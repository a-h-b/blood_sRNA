#!/bin/bash -l

#######################################################################################################################
# --------------------------------------------------- small RNA Analysis ----------------------------------------------
# ---------------------------------- Patrick May's version for pre-processing, November 2016 --------------------------
#  based on the BEar analysis script adapted by Anke Katrin Wienecke-Baldacchino in July 2016 from scripts by D. Yusuf
#######################################################################################################################

# this script documents the initial steps of the sRNA sequence analyis
# all necessary directories are generated on the fly
# besides some scripts needed to run this pipeline, all other scripts needed are generated on the fly
# note the setting of absolute paths in lines labeld with #absolutePaths

# --------------------------------  dependencies:
# - bedtools
# - fastx-toolkit
# - samtools
# - parallel
# - blast (makeblastdb, blastn)
# - FastQC
# - numpy (for cmc.py --> weighted count calculation)

#on University of Luxembourgs GAIA cluster:
module use $RESIF_ROOTINSTALL/lcsb/modules/all
module load bio/BEDTools/2.23.0-goolf-1.4.10
module load bio/FASTX-Toolkit/0.0.14-goolf-1.4.10
module load bio/FastQC/0.11.2
module load tools/parallel/20130122-goolf-1.4.10
module load bio/SAMtools/1.2-ictce-5.3.0
module use $RESIF_ROOTINSTALL/core/modules/all
module load math/numpy/1.8.0-ictce-5.3.0-Python-2.7.5
module load bio/BLAST+/2.2.28-goolf-1.4.10

# --------------------------------  scripts/files needed to run the pipeline:
scriptsdir=absolute_path_to_scripts #absolutePaths
# - clean_lib.py
# - novoindex/novoalign (commercial)


# --------------------------------  scripts/files generated by the pipeline:
# - fastx_clipper_parallel.sh / fastx_clipper_parallel.log
# - fastq_quality_trimmer.log
# - fastq_quality_filter.log
# - fastx_collapser.log
# - makeAlignmentHuman.sh / makeAlignmentHuman.log
# - extractUnmappedReadsSalmonella.sh


# --------------------------------  directories generated
# ./fastq
# ./QC
# ./cln.adapt.1
# ./cln.adapt.2
# ./cln.filt
# ./cln.trim
# ./aln_hg38
# ./aln_salmonella
# ./uniq_fasta
# ./unmapped_human
# ./unmapped_salmonella

#-----------------------------------------------------------------------------------------------------------------------
#                                                  START PIPELINE
#-----------------------------------------------------------------------------------------------------------------------
id=${PWD##*/}
sample=`grep $id ../../ids | cut -f 1`

##directory with the original fastq-files
rawDirectory=/absolute_path_to_raw_data #absolutePaths
rawData="$rawDirectory/$sample" 

##directory which holds: salmonella.fa, salmonella_genome.nix (novoindex-file, if already existing), salmonella.gtf
data="/absolute_path_to_salmonella_genome" #absolutePaths

############################################## PREPARE INPUT DATA ######################################################

mkdir fastq

zcat $rawData/*fastq.gz >fastq/$sample.fastq

######################################################## QC ############################################################

# --------------------------------------------- initial FastQC check ---------------------------------------------------
mkdir QC
parallel --gnu fastqc --extract -o QC {} ::: fastq/*.fastq

# --------------------------------------------- cut adapters and check -------------------------------------------------
mkdir cln.adapt.1
cd cln.adapt.1
#primer_contamination.csv generated, extracted from fastqc report
$scriptsdir/clean_lib.py -t ../QC/*/fastqc_data.txt
#take top sequence
##LINUX: 
grep primer_seq primer_contamination.csv | sed 's/\t/\n/g'| head -2 | tail -1 > contaminant_top
##MAC grep primer_seq primer_contamination.csv | tr '\t' '\n'| head -2 | tail -1 > contaminant_top
#generate script extracting the top enriched sequence and pipe it to fastx_collapser
more contaminant_top | awk '{print "parallel --gnu fastx_clipper -Q33 -a "$1"  -l 14 -v -i {} -o {/.}.fq ::: ../fastq/*.fastq"}' > fastx_clipper_parallel.sh
sh fastx_clipper_parallel.sh > fastx_clipper_parallel.log
curfastq=cln.adapt.1
cd ..
# original fastq-files can be zipped to save disk space
gzip fastq/*.fastq

# --------------------------------------------- second FastQC check ----------------------------------------------------

#make second fastQC run to check whether still adapter sequences or any other enriched sequence is in fastq-files
mkdir -p QC/1
parallel --gnu fastqc --extract -o QC/1 {} ::: $curfastq/*.fq

mkdir cln.adapt.2
cd cln.adapt.2

#primer_contamination.csv generated, extracted from fastqc report
$scriptsdir/clean_lib.py -t ../QC/1/*/fastqc_data.txt
#take top sequence
grep primer_seq primer_contamination.csv | sed 's/\t/\n/g'| head -2 | tail -1 > contaminant_top
stop=`grep primer_seq contaminant_top`
if [ -z $stop ] 
then
    more contaminant_top | awk '{print "parallel --gnu fastx_clipper -Q33 -a "$1"  -l 14 -v -i {} -o {/.}.fq ::: ../'$curfastq'/*.fq"}' > fastx_clipper_parallel.sh
    sh fastx_clipper_parallel.sh > fastx_clipper_parallel.log

    curfastq=cln.adapt.2
fi
cd ..

# ---------------------------------- trim clean sequences based on base quality ----------------------------------------

mkdir -p cln.trim
#Following the visualization of length distribution of sequences in all fastq files produced by fastqc, a length threshold of 14 was determined.
# A quality threshold of 25 phred score was used.
parallel --gnu fastq_quality_trimmer -Q33 -v -t 25 -l 14 -i {} -o cln.trim/{/.}_trim.fq ::: $curfastq/*.fq >> fastq_quality_trimmer.log

# clipped fastq-files from 1st QC can be zipped to save disk space
gzip $curfastq/*.fq
# ---------------------------------------------- third FastQC check ----------------------------------------------------

#check quality of trimmed sequences
curfastq=cln.trim
mkdir -p QC/trim
parallel --gnu fastqc --extract -o QC/trim {} ::: $curfastq/*.fq

# ------------------------------------- filter reads based on base quality ---------------------------------------------

mkdir -p cln.filt
#Sequences were filtered with a phred score of 25 throughout the read.
parallel --gnu fastq_quality_filter -Q33 -v -q 25 -p 100 -i {} -o cln.filt/{/.}.fq ::: $curfastq/*.fq >> fastq_quality_filter.log

# trimmed fastq-files can be zipped to save disk space
gzip $curfastq/*.fq
# ---------------------------------------------- fourth FastQC check ----------------------------------------------------

#check quality of quality filtered sequences
curfastq=cln.filt
mkdir -p QC/filt
parallel --gnu fastqc --extract -o QC/filt {} ::: $curfastq/*.fq

# ------------------------ merge all repeated sequences to one representative (performance thing) ----------------------

#This step is to merge all repeated sequences into unique tags maintaining the counts.
# Since we follow strict preprocessing, during mapping we use the fasta files generated in this step.
# No quality information is needed anymore, therefore fasta format ok.
mkdir -p uniq_fasta
parallel --gnu fastx_collapser -v -i {} -o uniq_fasta/{/.}.fa ::: $curfastq/*.fq >> fastx_collapser.log

# filtered fastq-files can be zipped to save disk space
gzip $curfastq/*.fq

##################################################### ALIGNMENT ########################################################

# -------------------------------------- make Index for salmonella alignment -------------------------------------------

#novoindex -k 14 -s 2 -n salmonella_genome $data/salmonella_genome.nix $data/salmonella.genome.fa

# ------------------------------------------ align reads to salmonella -------------------------------------------------

mkdir -p aln_salmonella
cd aln_salmonella

ln -s $scriptsdir/novoalign 
# attention: absolute PATH to data dir!!!
ls -1 ../uniq_fasta/ | awk '{print "./novoalign -d /absolute_path_to_salmonella_genome/salmonella_genome.nix -f ../uniq_fasta/"$1" -t 60 -h -1 -l 6 -o SAM -r ALL -e 51 > "$1"_salmonella.sam"}' > makeAlignmentSalmonella.sh #absolutePaths
sh makeAlignmentSalmonella.sh 2>> makeAlignmentSalmonella.log  
cd ..

# --------------------------------- extract unmapped reads and map against hg38 ---------------------------------------

mkdir -p unmapped_salmonella
cd unmapped_salmonella
ls -1 ../aln_salmonella/ | grep ".sam" | awk '{print "samtools view -f4 ../aln_salmonella/"$1" | awk -F\"\t\" '"'"'{print \">\"$1\"\\n\"$10}'"'"' > "$1"_uM.fa"}' | sed 's/.sam_/_/g' > extractUnmappedReadsSalmonella.sh 
ls -1 ../aln_salmonella/ | grep ".sam" | awk '{print "samtools view -f4 ../aln_salmonella/"$1" > "$1"_uM.sam"}' >> extractUnmappedReadsSalmonella.sh 
sh extractUnmappedReadsSalmonella.sh
cd ..

# ------------------------------ align all reads not mapping salmonella against hg38 -----------------------------------

mkdir -p aln_hg38
cd aln_hg38

file=`ls -1 ../unmapped_salmonella/ | grep -P  "uM.fa$"`
echo $scriptsdir'/novoalign -d /absolute_path_to_hg38.novoindex/hg38.novoindex -f ../unmapped_salmonella/'$file' -t 60 -h -1 -l 6 -o SAM -r ALL -e 51 > '$file'_hg38.sam'  > makeAlignmentHuman.sh #absolutePaths
sh makeAlignmentHuman.sh 2>> makeAlignmentHuman.log
cd ..

